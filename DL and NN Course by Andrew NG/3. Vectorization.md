# 3. Vectorization:

- Vectorization:
Perform operations on entire arrays/matrices of data simultaneously, rather than running a series of loops. Utilize hardware capabilities and libraries like PyTorch, NumPy. 
****Eg: np.dot, np.log, np.abs, np.maximum
- Vectorizing Logistic Regression:
Z = np.dot(w.T, X) + b
Stack training inputs in a matrix X, compute all the Z values at once using a single code line.
Similarly, compute all the activation values at once using another line of code, this saves a lot of time and increases speed.

- Broadcasting:
Allows arrays of different shapes to be used in arithmetic operations by automatically expanding the smaller array to match shape of larger one, without actually copying data.
It enables efficient vectorized operations.

- Logistic Regression’s Cost Function:
If, y = 1: p(y|x) = ŷ
If, y = 0: p(y|x) = 1 - ŷ
log p(y|x) = ylogŷ + (1-y)log(1-ŷ) = - L(ŷ, y) (as log value increases, loss function decreases)

Cost Function on ‘m’ examples:
Defines how well our model fits the entire dataset by averaging the error over all examples.